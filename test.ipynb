{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "test = 'train'\n",
    "data = os.path.join(os.getcwd(),'data','%s.txt'%test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 25, 35, 1])\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.rand(20,1,35,15,19))\n",
    "conv = nn.Conv3d(1,25,(1,15,1))\n",
    "output = torch.max(conv(input),4)\n",
    "print((output[0]).data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(data,'r')\n",
    "lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = lines[0].split()\n",
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'it', 'was', \"n't\", 'black', 'monday']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_character = set()\n",
    "for line in lines:\n",
    "    for word in line.split():\n",
    "        for char in word:\n",
    "            total_character.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 15, 19])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1,15,19)\n",
    "l = [a,a,a,a,a,a,a]\n",
    "for ix in range(len(l)-1):\n",
    "    l[ix+1] = torch.cat((l[ix],l[ix+1]),0)\n",
    "l[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#': 44,\n",
       " '$': 17,\n",
       " '&': 1,\n",
       " \"'\": 36,\n",
       " '-': 11,\n",
       " '.': 12,\n",
       " '/': 37,\n",
       " '0': 40,\n",
       " '1': 10,\n",
       " '2': 13,\n",
       " '3': 3,\n",
       " '5': 20,\n",
       " '6': 22,\n",
       " '7': 33,\n",
       " '8': 24,\n",
       " '9': 7,\n",
       " '<': 14,\n",
       " '>': 25,\n",
       " 'N': 2,\n",
       " '\\\\': 30,\n",
       " 'a': 6,\n",
       " 'b': 35,\n",
       " 'c': 43,\n",
       " 'd': 8,\n",
       " 'e': 31,\n",
       " 'f': 16,\n",
       " 'g': 34,\n",
       " 'h': 0,\n",
       " 'i': 18,\n",
       " 'j': 15,\n",
       " 'k': 39,\n",
       " 'l': 5,\n",
       " 'm': 45,\n",
       " 'n': 23,\n",
       " 'o': 26,\n",
       " 'p': 41,\n",
       " 'q': 28,\n",
       " 'r': 4,\n",
       " 's': 21,\n",
       " 't': 9,\n",
       " 'u': 19,\n",
       " 'v': 42,\n",
       " 'w': 38,\n",
       " 'x': 32,\n",
       " 'y': 29,\n",
       " 'z': 27}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dict = {}\n",
    "for idx,char_ in enumerate(total_character):\n",
    "    char_dict[char_] = idx\n",
    "\n",
    "char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.7981 -0.5981\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.7981\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = torch.FloatTensor([[1,1.2]])\n",
    "\n",
    "log_softmax = nn.LogSoftmax()\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "target = Variable(torch.LongTensor([0]),requires_grad=False)\n",
    "\n",
    "b = log_softmax(pos)\n",
    "print(b)\n",
    "loss_function(b,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.9741\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross(pos,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_embed = torch.rand([28,19])\n",
    "lookup = torch.nn.Embedding(28,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(28, 15, padding_idx=0)\n",
    "input = Variable(torch.LongTensor([13,14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 9 \n",
       "-0.2150  0.2244  0.2522 -1.2223 -0.2297  1.0472 -0.7371 -0.6330  0.3411  0.7730\n",
       " 0.1522 -0.6260  1.0245  2.8601 -1.9866 -1.2335 -0.1158  1.1584 -0.0750  0.0458\n",
       "\n",
       "Columns 10 to 14 \n",
       " 0.7424 -1.1807  0.8771 -0.3156  0.1654\n",
       " 1.4261  0.3835  1.4153  0.6486 -1.1115\n",
       "[torch.FloatTensor of size 2x15]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(input).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "[13, 14]\n",
      "it\n",
      "[8, 19]\n",
      "was\n",
      "[22, 0, 18]\n",
      "n't\n",
      "[13, -58, 19]\n",
      "black\n",
      "[1, 11, 0, 2, 10]\n",
      "monday\n",
      "[12, 14, 13, 3, 0, 24]\n"
     ]
    }
   ],
   "source": [
    "wordIx_list = []\n",
    "for word in (line_list[0]):\n",
    "    word_idx = []\n",
    "    print(word)\n",
    "    for idx,string in enumerate(word):\n",
    "        word_idx.append(ord(string)-97)\n",
    "    print(word_idx)\n",
    "    wordIx_list.append(word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(['1','a','b',';']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordvector[:,ix] = embedding(Variable(torch.LongTensor([13]))).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13\n",
      "torch.Size([15]) torch.Size([1, 15])\n",
      "1 14\n",
      "torch.Size([15]) torch.Size([1, 15])\n"
     ]
    }
   ],
   "source": [
    "wordvector = torch.zeros(15,19)\n",
    "\n",
    "for i,ix in enumerate(wordIx_list[0]):\n",
    "    print(i,ix)\n",
    "    input = Variable(torch.LongTensor([ix]))\n",
    "    print(wordvector[:,i].shape, embedding(input).data.shape)\n",
    "    wordvector[:,i] = embedding(input).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 9 \n",
       "-0.2150  0.1522  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.2244 -0.6260  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.2522  1.0245  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "-1.2223  2.8601  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "-0.2297 -1.9866  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 1.0472 -1.2335  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "-0.7371 -0.1158  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "-0.6330  1.1584  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.3411 -0.0750  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.7730  0.0458  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.7424  1.4261  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "-1.1807  0.3835  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.8771  1.4153  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "-0.3156  0.6486  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.1654 -1.1115  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 10 to 18 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 15x19]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "characters = ['a''b''c''d''e''f''g''h''i''j''k''l''m''n''o''p''q''r''t''u''v''w''x''y''z']\n",
    "numbers = ['1''2''3''4''5''6''7''8''9''10''11''12''13''14''15''16''17''18''19''20''21''22''23''24']\n",
    "text = raw_input(' Write text: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = self.encoder(input)\n",
    "packed = pack_padded_sequence(embeddings, lengths, batch_first=True)\n",
    "output, hidden = self.rnn(packed, hidden)\n",
    "output, _ = pad_packed_sequence(output, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = torch.zeros((30,81,15,19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ix in range(embedding.shape[0]):\n",
    "    (embedding[ix,:(ix+1)*2]) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "\n",
       "Columns 13 to 18 \n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "    0     0     0     0     0     0\n",
       "[torch.FloatTensor of size 15x19]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', 'a', 'c', 'd', 'e', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 's', 't', 'u']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def flatten(l):\n",
    "\treturn list(itertools.chain.from_iterable(l))\n",
    "\n",
    "seqs = ['ghatmasala','nicela','chutpakodas']\n",
    "\n",
    "# make <pad> idx 0\n",
    "vocab = ['<pad>'] + sorted(list(set(flatten(seqs))))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 6, 1, 15, 10, 1, 14, 1, 9, 1],\n",
       " [11, 7, 2, 4, 9, 1],\n",
       " [2, 6, 16, 15, 13, 1, 8, 12, 3, 1, 14]]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make model\n",
    "embed = nn.Embedding(len(vocab), 10).cuda()\n",
    "lstm = nn.LSTM(10, 5).cuda()\n",
    "\n",
    "indexed_seqs = [[vocab.index(tok) for tok in seq]for seq in seqs]\n",
    "\n",
    "(indexed_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7f0e7669bef0>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def length(x):\n",
    "    return len(x)\n",
    "map(length,([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 10\n",
       "  6\n",
       " 11\n",
       "[torch.cuda.LongTensor of size 3 (GPU 0)]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the length of each seq in your batch\n",
    "seq_lengths = torch.cuda.LongTensor([10,6,11])\n",
    "seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump padding everywhere, and place seqs on the left.\n",
    "# NOTE: you only need a tensor as big as your longest sequence\n",
    "seq_tensor = Variable(torch.zeros((len(indexed_seqs), seq_lengths.max()))).long().cuda()\n",
    "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "    seq_tensor[idx, :seqlen] = torch.LongTensor(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    5     6     1    15    10     1    14     1     9     1     0\n",
       "   11     7     2     4     9     1     0     0     0     0     0\n",
       "    2     6    16    15    13     1     8    12     3     1    14\n",
       "[torch.cuda.LongTensor of size 3x11 (GPU 0)]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    2     6    16    15    13     1     8    12     3     1    14\n",
       "    5     6     1    15    10     1    14     1     9     1     0\n",
       "   11     7     2     4     9     1     0     0     0     0     0\n",
       "[torch.cuda.LongTensor of size 3x11 (GPU 0)]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SORT YOUR TENSORS BY LENGTH!\n",
    "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "seq_tensor = seq_tensor[perm_idx]\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 0\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 3 (GPU 0)]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    2     5    11\n",
       "    6     6     7\n",
       "   16     1     2\n",
       "   15    15     4\n",
       "   13    10     9\n",
       "    1     1     1\n",
       "    8    14     0\n",
       "   12     1     0\n",
       "    3     9     0\n",
       "    1     1     0\n",
       "   14     0     0\n",
       "[torch.cuda.LongTensor of size 11x3 (GPU 0)]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utils.rnn lets you give (B,L,D) tensors where B is the batch size, L is the maxlength, if you use batch_first=True\n",
    "# Otherwise, give (L,B,D) tensors\n",
    "seq_tensor = seq_tensor.transpose(0,1) # (B,L,D) -> (L,B,D)\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "  -2.1814 -0.6374 -0.8253 -0.2426  1.3999  0.8037 -0.3597 -0.9376 -0.2742\n",
       "  0.8864  0.4113  0.1987 -0.4049 -0.6064  1.6391 -0.3448 -0.9396 -0.3928\n",
       "  0.5873  0.1769  1.0438  0.0253 -0.5044 -0.5080 -1.4042  1.1235  2.1067\n",
       " -0.5829  0.3705 -0.6754  0.0218  0.3745  1.5032 -0.8463  1.1109 -0.5201\n",
       "  0.3475 -0.7264  0.0661  0.5092  1.0329 -1.0979  0.3328  0.8401  0.3117\n",
       "  0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340\n",
       "  0.3562  1.3960  0.6538 -0.5601 -2.2048  2.0548 -0.0852  1.7615  0.5751\n",
       "  0.2683  0.0346 -1.0761 -0.1982  1.5948  0.5453 -0.6330  0.6694  0.7814\n",
       " -1.9325 -0.6354  0.3001  0.1328 -0.7277 -1.4790 -0.0975  1.1177  0.0333\n",
       "  0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340\n",
       " -0.2568 -0.2977  0.6898  0.7353  0.7380  0.2172  0.7591  1.5388 -1.4510\n",
       "\n",
       "Columns 9 to 9 \n",
       "  -1.7111\n",
       " -0.6320\n",
       " -1.5991\n",
       " -1.5449\n",
       "  0.7860\n",
       " -0.4833\n",
       "  1.3640\n",
       " -0.2385\n",
       " -1.2832\n",
       " -0.4833\n",
       "  0.0895\n",
       "\n",
       "(1 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   1.7271 -0.8649 -0.8522  0.2990 -1.4795 -0.5041 -0.0475  1.4312  0.2056\n",
       "  0.8864  0.4113  0.1987 -0.4049 -0.6064  1.6391 -0.3448 -0.9396 -0.3928\n",
       "  0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340\n",
       " -0.5829  0.3705 -0.6754  0.0218  0.3745  1.5032 -0.8463  1.1109 -0.5201\n",
       "  1.3632 -0.3065  2.5197 -0.2054 -1.5119  0.2657  0.0277  0.1109  0.6282\n",
       "  0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340\n",
       " -0.2568 -0.2977  0.6898  0.7353  0.7380  0.2172  0.7591  1.5388 -1.4510\n",
       "  0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340\n",
       " -1.0235 -1.8683  0.1585 -0.6531 -1.4765  0.2877  0.1830 -1.6271 -0.8299\n",
       "  0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340\n",
       "  0.0563  0.5001  0.6367  1.0936  1.1460  0.6865 -3.3815 -1.0457 -2.3540\n",
       "\n",
       "Columns 9 to 9 \n",
       "  -0.8765\n",
       " -0.6320\n",
       " -0.4833\n",
       " -1.5449\n",
       "  0.2182\n",
       " -0.4833\n",
       "  0.0895\n",
       " -0.4833\n",
       "  1.7828\n",
       " -0.4833\n",
       " -0.5148\n",
       "\n",
       "(2 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "  -0.3328 -1.2071 -0.4408 -1.2495 -0.3990  0.3970 -0.2649  0.6121  0.5921\n",
       " -1.7854  0.3216 -0.8386 -0.4277 -0.5927  0.1465 -0.4199 -1.6056  0.2522\n",
       " -2.1814 -0.6374 -0.8253 -0.2426  1.3999  0.8037 -0.3597 -0.9376 -0.2742\n",
       " -1.1789  0.5534 -0.9006  1.3743 -0.4636  0.1884 -0.4787 -0.6760 -0.8100\n",
       " -1.0235 -1.8683  0.1585 -0.6531 -1.4765  0.2877  0.1830 -1.6271 -0.8299\n",
       "  0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340\n",
       "  0.0563  0.5001  0.6367  1.0936  1.1460  0.6865 -3.3815 -1.0457 -2.3540\n",
       "  0.0563  0.5001  0.6367  1.0936  1.1460  0.6865 -3.3815 -1.0457 -2.3540\n",
       "  0.0563  0.5001  0.6367  1.0936  1.1460  0.6865 -3.3815 -1.0457 -2.3540\n",
       "  0.0563  0.5001  0.6367  1.0936  1.1460  0.6865 -3.3815 -1.0457 -2.3540\n",
       "  0.0563  0.5001  0.6367  1.0936  1.1460  0.6865 -3.3815 -1.0457 -2.3540\n",
       "\n",
       "Columns 9 to 9 \n",
       "  -1.2245\n",
       " -0.1728\n",
       " -1.7111\n",
       "  1.7130\n",
       "  1.7828\n",
       " -0.4833\n",
       " -0.5148\n",
       " -0.5148\n",
       " -0.5148\n",
       " -0.5148\n",
       " -0.5148\n",
       "[torch.cuda.FloatTensor of size 3x11x10 (GPU 0)]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embed your sequences\n",
    "seq_tensor = embed(seq_tensor)\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pack them up nicely\n",
    "packed_input = pack_padded_sequence(seq_tensor, seq_lengths.cpu().numpy(),batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 10,  6])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(seq_lengths.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       "-2.1814 -0.6374 -0.8253 -0.2426  1.3999  0.8037 -0.3597 -0.9376 -0.2742 -1.7111\n",
       " 1.7271 -0.8649 -0.8522  0.2990 -1.4795 -0.5041 -0.0475  1.4312  0.2056 -0.8765\n",
       "-0.3328 -1.2071 -0.4408 -1.2495 -0.3990  0.3970 -0.2649  0.6121  0.5921 -1.2245\n",
       " 0.8864  0.4113  0.1987 -0.4049 -0.6064  1.6391 -0.3448 -0.9396 -0.3928 -0.6320\n",
       " 0.8864  0.4113  0.1987 -0.4049 -0.6064  1.6391 -0.3448 -0.9396 -0.3928 -0.6320\n",
       "-1.7854  0.3216 -0.8386 -0.4277 -0.5927  0.1465 -0.4199 -1.6056  0.2522 -0.1728\n",
       " 0.5873  0.1769  1.0438  0.0253 -0.5044 -0.5080 -1.4042  1.1235  2.1067 -1.5991\n",
       " 0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340 -0.4833\n",
       "-2.1814 -0.6374 -0.8253 -0.2426  1.3999  0.8037 -0.3597 -0.9376 -0.2742 -1.7111\n",
       "-0.5829  0.3705 -0.6754  0.0218  0.3745  1.5032 -0.8463  1.1109 -0.5201 -1.5449\n",
       "-0.5829  0.3705 -0.6754  0.0218  0.3745  1.5032 -0.8463  1.1109 -0.5201 -1.5449\n",
       "-1.1789  0.5534 -0.9006  1.3743 -0.4636  0.1884 -0.4787 -0.6760 -0.8100  1.7130\n",
       " 0.3475 -0.7264  0.0661  0.5092  1.0329 -1.0979  0.3328  0.8401  0.3117  0.7860\n",
       " 1.3632 -0.3065  2.5197 -0.2054 -1.5119  0.2657  0.0277  0.1109  0.6282  0.2182\n",
       "-1.0235 -1.8683  0.1585 -0.6531 -1.4765  0.2877  0.1830 -1.6271 -0.8299  1.7828\n",
       " 0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340 -0.4833\n",
       " 0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340 -0.4833\n",
       " 0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340 -0.4833\n",
       " 0.3562  1.3960  0.6538 -0.5601 -2.2048  2.0548 -0.0852  1.7615  0.5751  1.3640\n",
       "-0.2568 -0.2977  0.6898  0.7353  0.7380  0.2172  0.7591  1.5388 -1.4510  0.0895\n",
       " 0.2683  0.0346 -1.0761 -0.1982  1.5948  0.5453 -0.6330  0.6694  0.7814 -0.2385\n",
       " 0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340 -0.4833\n",
       "-1.9325 -0.6354  0.3001  0.1328 -0.7277 -1.4790 -0.0975  1.1177  0.0333 -1.2832\n",
       "-1.0235 -1.8683  0.1585 -0.6531 -1.4765  0.2877  0.1830 -1.6271 -0.8299  1.7828\n",
       " 0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340 -0.4833\n",
       " 0.6607  1.0054 -0.7134 -1.0784  1.3174  0.0589 -0.3449  0.9434 -0.0340 -0.4833\n",
       "-0.2568 -0.2977  0.6898  0.7353  0.7380  0.2172  0.7591  1.5388 -1.4510  0.0895\n",
       "[torch.cuda.FloatTensor of size 27x10 (GPU 0)]\n",
       ", batch_sizes=[3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# throw them through your LSTM (remember to give batch_first=True here if you packed with it)\n",
    "packed_output, (ht, ct) = lstm(packed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       " 0.0474 -0.3261  0.2341 -0.2337  0.0455\n",
       " 0.0736 -0.0084  0.2763 -0.0207 -0.0440\n",
       " 0.0495 -0.3617  0.2309 -0.2148 -0.0199\n",
       "-0.0306 -0.2182  0.1954  0.0038 -0.1237\n",
       "-0.0245 -0.0705  0.1903  0.0445 -0.1593\n",
       " 0.2080 -0.4452  0.3396 -0.3294 -0.0977\n",
       "-0.0047 -0.3086  0.3278 -0.0522 -0.1474\n",
       " 0.0560 -0.0589  0.2464  0.2091  0.0832\n",
       " 0.3188 -0.4151  0.3140 -0.5176  0.0119\n",
       "-0.0160 -0.1152  0.2412 -0.0132 -0.0732\n",
       "-0.0766 -0.0738  0.2406  0.1491  0.0398\n",
       " 0.0037 -0.0213  0.0681 -0.2738  0.0868\n",
       " 0.0278 -0.0131  0.3937  0.0733  0.1341\n",
       "-0.0351 -0.1415  0.3634  0.0498 -0.0971\n",
       "-0.0288 -0.3774 -0.0042 -0.1664 -0.0092\n",
       " 0.0944 -0.0305  0.2604  0.2065  0.2155\n",
       " 0.0434 -0.0705  0.2544  0.2448  0.0931\n",
       " 0.0935 -0.1048  0.2535  0.0071  0.1777\n",
       "-0.1142 -0.0094 -0.0568  0.0678 -0.3383\n",
       "-0.2463  0.0114  0.3406  0.1190  0.0922\n",
       "-0.2456 -0.0568  0.1804  0.2503  0.0564\n",
       "-0.0090 -0.0128  0.2750  0.3139  0.2152\n",
       "-0.0105 -0.3006  0.5164 -0.0036  0.0810\n",
       "-0.0718 -0.4389  0.1362  0.1092  0.0120\n",
       " 0.1316 -0.0988  0.2831  0.1640  0.1885\n",
       " 0.0696 -0.1172  0.2646  0.2515  0.1818\n",
       "-0.2066  0.0018  0.3464  0.1039  0.1128\n",
       "[torch.cuda.FloatTensor of size 27x5 (GPU 0)]\n",
       ", batch_sizes=[3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.0474 -0.3261  0.2341 -0.2337  0.0455\n",
       "  0.0736 -0.0084  0.2763 -0.0207 -0.0440\n",
       "  0.0495 -0.3617  0.2309 -0.2148 -0.0199\n",
       "\n",
       "(1 ,.,.) = \n",
       " -0.0306 -0.2182  0.1954  0.0038 -0.1237\n",
       " -0.0245 -0.0705  0.1903  0.0445 -0.1593\n",
       "  0.2080 -0.4452  0.3396 -0.3294 -0.0977\n",
       "\n",
       "(2 ,.,.) = \n",
       " -0.0047 -0.3086  0.3278 -0.0522 -0.1474\n",
       "  0.0560 -0.0589  0.2464  0.2091  0.0832\n",
       "  0.3188 -0.4151  0.3140 -0.5176  0.0119\n",
       "\n",
       "(3 ,.,.) = \n",
       " -0.0160 -0.1152  0.2412 -0.0132 -0.0732\n",
       " -0.0766 -0.0738  0.2406  0.1491  0.0398\n",
       "  0.0037 -0.0213  0.0681 -0.2738  0.0868\n",
       "\n",
       "(4 ,.,.) = \n",
       "  0.0278 -0.0131  0.3937  0.0733  0.1341\n",
       " -0.0351 -0.1415  0.3634  0.0498 -0.0971\n",
       " -0.0288 -0.3774 -0.0042 -0.1664 -0.0092\n",
       "\n",
       "(5 ,.,.) = \n",
       "  0.0944 -0.0305  0.2604  0.2065  0.2155\n",
       "  0.0434 -0.0705  0.2544  0.2448  0.0931\n",
       "  0.0935 -0.1048  0.2535  0.0071  0.1777\n",
       "\n",
       "(6 ,.,.) = \n",
       " -0.1142 -0.0094 -0.0568  0.0678 -0.3383\n",
       " -0.2463  0.0114  0.3406  0.1190  0.0922\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "(7 ,.,.) = \n",
       " -0.2456 -0.0568  0.1804  0.2503  0.0564\n",
       " -0.0090 -0.0128  0.2750  0.3139  0.2152\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "(8 ,.,.) = \n",
       " -0.0105 -0.3006  0.5164 -0.0036  0.0810\n",
       " -0.0718 -0.4389  0.1362  0.1092  0.0120\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "(9 ,.,.) = \n",
       "  0.1316 -0.0988  0.2831  0.1640  0.1885\n",
       "  0.0696 -0.1172  0.2646  0.2515  0.1818\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "(10,.,.) = \n",
       " -0.2066  0.0018  0.3464  0.1039  0.1128\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "[torch.cuda.FloatTensor of size 11x3x5 (GPU 0)]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unpack your output if required\n",
    "output, _ = pad_packed_sequence(packed_output)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.2066  0.0018  0.3464  0.1039  0.1128\n",
       " 0.0696 -0.1172  0.2646  0.2515  0.1818\n",
       " 0.0935 -0.1048  0.2535  0.0071  0.1777\n",
       "[torch.cuda.FloatTensor of size 3x5 (GPU 0)]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_list = [['1','2','3','4','5'],['2','3','4'],['5','6','7','8','3','5','7','2']]\n",
    "line_list.sort(key=len,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "already counted a million dimensions in a given sequence. Most likely your items are also sequences and there's no way to infer how many dimension should the tensor have",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-306-5605d93b1e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: already counted a million dimensions in a given sequence. Most likely your items are also sequences and there's no way to infer how many dimension should the tensor have"
     ]
    }
   ],
   "source": [
    "torch.FloatTensor(line_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  3\n",
       " 3  4\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 525])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_conv = Variable(torch.rand(20,525))\n",
    "out_conv = out_conv.view(1,20,525)\n",
    "out_conv.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(525,300,batch_first=True)\n",
    "h, c = lstm(out_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 300])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Variable(torch.rand(20,525),requires_grad=False).view([20,1,525])\n",
    "h,c = lstm(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 300])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = Variable(torch.rand(20,9999))\n",
    "target = Variable(torch.LongTensor([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]))\n",
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = loss_function(output,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax()\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size nBatch x nClasses = 3 x 5\n",
    "input = Variable(torch.randn(3, 5), requires_grad=True)\n",
    "# each element in target has to have 0 <= value < nclasses\n",
    "target = Variable(torch.LongTensor([1, 0, 4]))\n",
    "output = loss(m(input), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5960  2.3376  2.8304  2.1207  1.7517\n",
       " 1.6352  1.7320  1.4211  2.0278  1.3661\n",
       "[torch.FloatTensor of size 2x5]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Variable(torch.randn(2, 5), requires_grad=False)\n",
    "-m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = Variable(torch.LongTensor([1,2]))\n",
    "#output = loss(m(input), target)\n",
    "#output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.8793\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "output = cross_entropy(input,target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.87935"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2.3376+1.4211)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_list = [[1,2,3],[1,2,3,4],[1,2,3,4,5,],[1,2,3]]\n",
    "empty_list = []\n",
    "merged_list = [empty_list + nlist for nlist in line_list]\n",
    "\n",
    "a = line_list[0] + line_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor(3,5)\n",
    "a.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 34, 50])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Variable(torch.rand(20,1,34,15,19))\n",
    "cnn1 = nn.Conv3d(1,25,(1,15,3))\n",
    "cnn2 = nn.Conv3d(1,50,(1,15,4))\n",
    "linear = nn.Linear(75,50)\n",
    "x1 = torch.max(cnn1(input),4)[0]\n",
    "x2 = torch.max(cnn2(input),4)[0]\n",
    "cnn_input = torch.squeeze(torch.cat((x1,x2),1)).transpose(1,2)\n",
    "h = linear(cnn_input)\n",
    "h.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(525,300,1,batch_first=True)\n",
    "lstm_input = Variable(torch.rand(20,34,525))\n",
    "out,(h,c) = lstm(lstm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 300])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0].data.shape\n",
    "h.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 34, 300])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4   5   6\n",
      "  3   8   5  16   3   6\n",
      "  5   6  10   7   4   2\n",
      "[torch.FloatTensor of size 3x6]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 5\n",
       " 3\n",
       " 2\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_test = torch.Tensor([[1,2,3,4,5,6],[3,8,5,16,3,6],[5,6,10,7,4,2]])\n",
    "softmax = nn.LogSoftmax()\n",
    "print(out_test)\n",
    "out = softmax(out_test)\n",
    "true = Variable(torch.max(out,1)[1].data)\n",
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 5.4562e+00  4.4562e+00  3.4562e+00  2.4562e+00  1.4562e+00  4.5619e-01\n",
       " 1.3000e+01  8.0004e+00  1.1000e+01  4.0200e-04  1.3000e+01  1.0000e+01\n",
       " 5.0748e+00  4.0748e+00  7.4787e-02  3.0748e+00  6.0748e+00  8.0748e+00\n",
       "[torch.FloatTensor of size 3x6]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-out.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.1771\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "loss = loss_function(out,true)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17712633333333336"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4.5619e-01 + 4.0200e-04 + 7.4787e-02) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3030476700979148"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(9/34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'obj/asd.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-492-8b277ae59eec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'asd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-491-b9cf1f1eeb40>\u001b[0m in \u001b[0;36msave_obj\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'obj/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'obj/asd.pkl'"
     ]
    }
   ],
   "source": [
    "test_dict = {'a':0,'b':1}\n",
    "save_obj(test_dict,'asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('filename.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('filename.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "os.path.isfile('filename.pickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.Tensor(np.array([1.,2.,3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(30,20,10)\n",
    "a[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 270, 50])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(20,270,50)\n",
    "b = torch.rand(20,270,50)\n",
    "c = torch.cat((a,b),0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 500)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmax = (np.random.normal(size=(10,500)))\n",
    "tmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "l = [0,1,3]\n",
    "loss += []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 0\n",
       " 1\n",
       "[torch.ByteTensor of size 3]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.LongTensor([1,2,3])\n",
    "b = torch.LongTensor([1,0,3])\n",
    "a==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (Conv): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (Linear): Linear (100 -> 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.Conv = nn.Conv2d(1,10,5)\n",
    "        self.Linear = nn.Linear(100,2)\n",
    "    def forward(self,input):\n",
    "        conv = self.Conv(input)\n",
    "        #out = self.Linear(conv)\n",
    "        return conv\n",
    "net = Net()\n",
    "print(net)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 96, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "test_input = Variable(torch.rand(10,1,100,5))\n",
    "out = net(test_input)\n",
    "out.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.112470279863166"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(90/34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.4131591025766"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 148.4132\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(Variable(torch.FloatTensor([5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199500"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20*35*15*19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10*2678*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "a[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 30])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand([20,30])\n",
    "b[1:30,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.rand([20,35,525]),requires_grad=False)\n",
    "lstm = nn.LSTM(525,300)\n",
    "h_0 = Variable(torch.zeros([1,20,300]))\n",
    "c_0 = Variable(torch.zeros([1,20,300]))\n",
    "\n",
    "output, (h,c) = lstm(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 35, 300])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.LongTensor([1,2,3,4,5]).unsqueeze(0)\n",
    "b = torch.LongTensor([3,4,5,6,7]).unsqueeze(0)\n",
    "a = torch.cat((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.rand(20,34,9999))\n",
    "input = input.view(680,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([680, 9999])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "output = Variable(torch.rand(5,10))\n",
    "target = Variable(torch.LongTensor([0,1,2,1,3]))\n",
    "print(output.data.shape,target.data.shape)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "loss = loss_f(output,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 199.1618\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.FloatTensor([180/34]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
